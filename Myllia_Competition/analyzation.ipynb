{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d3a68e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adata: AnnData object with n_obs × n_vars = 17882 × 19226\n",
      "    obs: 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'sgrna_id', 'sgrna_symbol', 'channel'\n",
      "    var: 'features'\n",
      "X type: <class 'scipy.sparse._csr.csr_matrix'> sparse: True\n",
      "\n",
      "obs columns: ['nCount_RNA', 'nFeature_RNA', 'percent.mt', 'sgrna_id', 'sgrna_symbol', 'channel']\n",
      "var shape: (19226, 1)\n",
      "var_names example: ['A1BG', 'A1CF', 'A2M', 'A2ML1', 'A3GALT2']\n",
      "\n",
      "# unique sgrna_symbol: 81\n",
      "top 10 sgrna_symbol:\n",
      " sgrna_symbol\n",
      "non-targeting    1026\n",
      "MAPK1             447\n",
      "KDM5C             428\n",
      "FLNA              415\n",
      "HDAC4             410\n",
      "HSPA4             382\n",
      "RUNX1             374\n",
      "PAGR1             355\n",
      "PAXIP1            350\n",
      "INSIG1            348\n",
      "Name: count, dtype: int64\n",
      "non-targeting count: 1026\n"
     ]
    }
   ],
   "source": [
    "import anndata as ad\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "adata = ad.read_h5ad(\"Data/training_cells.h5ad\")  # adjust path if needed\n",
    "print(\"adata:\", adata)\n",
    "print(\"X type:\", type(adata.X), \"sparse:\", sparse.issparse(adata.X))\n",
    "\n",
    "print(\"\\nobs columns:\", adata.obs.columns.tolist())\n",
    "print(\"var shape:\", adata.var.shape)\n",
    "print(\"var_names example:\", adata.var_names[:5].tolist())\n",
    "\n",
    "# Basic group counts\n",
    "sgrna_col = \"sgrna_symbol\" if \"sgrna_symbol\" in adata.obs.columns else None\n",
    "if sgrna_col:\n",
    "    vc = adata.obs[sgrna_col].astype(str).value_counts()\n",
    "    print(\"\\n# unique sgrna_symbol:\", vc.shape[0])\n",
    "    print(\"top 10 sgrna_symbol:\\n\", vc.head(10))\n",
    "    print(\"non-targeting count:\", int(vc.get(\"non-targeting\", 0)))\n",
    "else:\n",
    "    print(\"\\nNo sgrna_symbol column found. Tell me what the perturbation column is called.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4876904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control cells: 1026\n",
      "Missing genes from h5ad vs means: 0\n",
      "First missing (if any): []\n",
      "\n",
      "SVD EVR:\n",
      "  cumulative@16 : 0.26657429337501526\n",
      "  cumulative@32 : 0.3023926913738251\n",
      "  cumulative@64 : 0.35523587465286255\n",
      "  cumulative@128: 0.4424440562725067\n",
      "corr(SVD1, nCount_RNA): 0.9738853720362605\n",
      "corr(SVD1, percent.mt): -0.10616440498751527\n",
      "\n",
      "Top 10 SVD(1,2) radius outliers:\n",
      "  cell_index=475  r=155.4046  nCount_RNA=51610.0  percent.mt=4.194923464444876\n",
      "  cell_index=715  r=149.4625  nCount_RNA=50255.0  percent.mt=4.208536464033429\n",
      "  cell_index=721  r=147.8066  nCount_RNA=45949.0  percent.mt=3.717164682582864\n",
      "  cell_index=357  r=146.1689  nCount_RNA=45325.0  percent.mt=5.844456701599559\n",
      "  cell_index=782  r=145.5938  nCount_RNA=51079.0  percent.mt=3.0521349282483996\n",
      "  cell_index=402  r=142.7757  nCount_RNA=41929.0  percent.mt=7.569939659901262\n",
      "  cell_index=814  r=142.0721  nCount_RNA=44351.0  percent.mt=5.251290838988974\n",
      "  cell_index=942  r=142.0457  nCount_RNA=39325.0  percent.mt=5.317228226319135\n",
      "  cell_index=290  r=141.9059  nCount_RNA=42249.0  percent.mt=7.1978034983076515\n",
      "  cell_index=691  r=141.5249  nCount_RNA=41266.0  percent.mt=4.296515291038627\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import pandas as pd\n",
    "SEED = 6\n",
    "EMBED_DIM = 128\n",
    "\n",
    "# Reload needed objects\n",
    "df_means = pd.read_csv(\"data/training_data_means.csv\")\n",
    "gene_cols = [c for c in df_means.columns if c != \"pert_symbol\"]\n",
    "\n",
    "adata = ad.read_h5ad(\"Data/training_cells.h5ad\")\n",
    "ctrl_mask = (adata.obs[\"sgrna_symbol\"].astype(str) == \"non-targeting\")\n",
    "adata_ctrl = adata[ctrl_mask].copy()\n",
    "print(\"Control cells:\", adata_ctrl.n_obs)\n",
    "\n",
    "# Align genes with gene_cols order\n",
    "varnames = adata_ctrl.var_names.astype(str).tolist()\n",
    "gene_to_idx = {g:i for i,g in enumerate(varnames)}\n",
    "missing = [g for g in gene_cols if g not in gene_to_idx]\n",
    "print(\"Missing genes from h5ad vs means:\", len(missing))\n",
    "print(\"First missing (if any):\", missing[:10])\n",
    "\n",
    "ordered_idx = [gene_to_idx[g] for g in gene_cols if g in gene_to_idx]\n",
    "adata_ctrl = adata_ctrl[:, ordered_idx].copy()\n",
    "\n",
    "X = adata_ctrl.X\n",
    "if sparse.issparse(X):\n",
    "    X = X.tocsr(copy=True)\n",
    "    X.data = np.log2(X.data + 1.0).astype(np.float32)\n",
    "else:\n",
    "    X = np.log2(X.astype(np.float32) + 1.0)\n",
    "\n",
    "# SVD\n",
    "svd = TruncatedSVD(n_components=EMBED_DIM, random_state=SEED)\n",
    "Z = svd.fit_transform(X)\n",
    "\n",
    "evr = svd.explained_variance_ratio_\n",
    "print(\"\\nSVD EVR:\")\n",
    "print(\"  cumulative@16 :\", float(np.cumsum(evr)[15]))\n",
    "print(\"  cumulative@32 :\", float(np.cumsum(evr)[31]))\n",
    "print(\"  cumulative@64 :\", float(np.cumsum(evr)[63]))\n",
    "print(\"  cumulative@128:\", float(np.cumsum(evr)[127]))\n",
    "\n",
    "# QC correlations if present\n",
    "for col in [\"nCount_RNA\", \"percent.mt\"]:\n",
    "    if col in adata_ctrl.obs.columns:\n",
    "        r = np.corrcoef(Z[:,0], adata_ctrl.obs[col].to_numpy())[0,1]\n",
    "        print(f\"corr(SVD1, {col}):\", float(r))\n",
    "\n",
    "# Find outliers in SVD space by radius\n",
    "r = np.sqrt(Z[:,0]**2 + Z[:,1]**2)\n",
    "idx = np.argsort(r)[-10:][::-1]\n",
    "print(\"\\nTop 10 SVD(1,2) radius outliers:\")\n",
    "for j in idx:\n",
    "    row = adata_ctrl.obs.iloc[j]\n",
    "    extras = []\n",
    "    if \"nCount_RNA\" in row: extras.append(f\"nCount_RNA={row['nCount_RNA']}\")\n",
    "    if \"percent.mt\" in row: extras.append(f\"percent.mt={row['percent.mt']}\")\n",
    "    print(f\"  cell_index={j}  r={float(r[j]):.4f}  \" + \"  \".join(extras))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "443ff445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abs(delta) quantiles: [0.015714123845100403, 0.039262594655156136, 0.07378450930118562, 0.10317319482564924, 0.1939082145690912]\n",
      "Output PCA cumulative@8: 0.5560860633850098\n",
      "Output PCA cumulative@16: 0.6922448873519897\n",
      "Output PCA cumulative@32: 0.831583559513092\n",
      "Output PCA cumulative@48: 0.9131585359573364\n",
      "Output PCA cumulative@64: 0.966091513633728\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "df_means = pd.read_csv(\"data/training_data_means.csv\")\n",
    "gene_cols = [c for c in df_means.columns if c != \"pert_symbol\"]\n",
    "baseline_mask = (df_means[\"pert_symbol\"].astype(str) == \"non-targeting\")\n",
    "\n",
    "x_base = df_means.loc[baseline_mask, gene_cols].mean(axis=0).to_numpy(np.float32)\n",
    "df_train = df_means.loc[~baseline_mask].reset_index(drop=True)\n",
    "D = df_train[gene_cols].to_numpy(np.float32) - x_base[None, :]\n",
    "\n",
    "# How \"sparse\" are deltas numerically?\n",
    "absD = np.abs(D)\n",
    "print(\"abs(delta) quantiles:\", np.quantile(absD, [0.5, 0.75, 0.9, 0.95, 0.99]).tolist())\n",
    "\n",
    "# PCA explained variance on outputs\n",
    "pca = PCA(n_components=min(80, D.shape[0]), random_state=0)\n",
    "pca.fit(D)\n",
    "cum = np.cumsum(pca.explained_variance_ratio_)\n",
    "for k in [8, 16, 32, 48, 64]:\n",
    "    if k <= len(cum):\n",
    "        print(f\"Output PCA cumulative@{k}: {float(cum[k-1])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7654461d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train genes: 80\n",
      "Train genes missing from gene_columns: 8\n",
      "Missing list: ['BRD4', 'CHD4', 'DNAJA3', 'INO80', 'KAT8', 'KDM4A', 'PMEL', 'SETD1A']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_means = pd.read_csv(\"data/training_data_means.csv\")\n",
    "gene_columns = [c for c in df_means.columns if c != \"pert_symbol\"]\n",
    "baseline_mask = df_means[\"pert_symbol\"].astype(str) == \"non-targeting\"\n",
    "\n",
    "df_train = df_means.loc[~baseline_mask].reset_index(drop=True)\n",
    "train_genes = df_train[\"pert_symbol\"].astype(str).tolist()\n",
    "\n",
    "missing_train = sorted({g for g in train_genes if g not in gene_columns})\n",
    "print(\"Train genes:\", len(train_genes))\n",
    "print(\"Train genes missing from gene_columns:\", len(missing_train))\n",
    "print(\"Missing list:\", missing_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c844a162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train genes: 80\n",
      "Train genes missing from gene_columns: 8\n",
      "Missing list: ['BRD4', 'CHD4', 'DNAJA3', 'INO80', 'KAT8', 'KDM4A', 'PMEL', 'SETD1A']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_means = pd.read_csv(\"data/training_data_means.csv\")\n",
    "gene_columns = [c for c in df_means.columns if c != \"pert_symbol\"]\n",
    "baseline_mask = df_means[\"pert_symbol\"].astype(str) == \"non-targeting\"\n",
    "\n",
    "df_train = df_means.loc[~baseline_mask].reset_index(drop=True)\n",
    "train_genes = df_train[\"pert_symbol\"].astype(str).tolist()\n",
    "\n",
    "missing_train = sorted({g for g in train_genes if g not in gene_columns})\n",
    "print(\"Train genes:\", len(train_genes))\n",
    "print(\"Train genes missing from gene_columns:\", len(missing_train))\n",
    "print(\"Missing list:\", missing_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7c14507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control cells after 99% depth trim: 1015\n",
      "corr(SVD1, nCount_RNA): 0.26806640619368727\n",
      "corr(SVD1, percent.mt): -0.2649107023641811\n",
      "cumEVR@32: 0.1406271904706955\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "from scipy import sparse\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "SEED = 6\n",
    "EMBED_DIM = 64  # try 32/64 later\n",
    "\n",
    "df_means = pd.read_csv(\"data/training_data_means.csv\")\n",
    "gene_columns = [c for c in df_means.columns if c != \"pert_symbol\"]\n",
    "\n",
    "adata = ad.read_h5ad(\"Data/training_cells.h5ad\")\n",
    "ctrl_mask = adata.obs[\"sgrna_symbol\"].astype(str) == \"non-targeting\"\n",
    "adata_ctrl = adata[ctrl_mask].copy()\n",
    "\n",
    "# Keep only the 5127 target genes and order them\n",
    "varnames = adata_ctrl.var_names.astype(str).tolist()\n",
    "gene_to_idx = {g:i for i,g in enumerate(varnames)}\n",
    "ordered_idx = [gene_to_idx[g] for g in gene_columns]\n",
    "adata_ctrl = adata_ctrl[:, ordered_idx].copy()\n",
    "\n",
    "# Optional: drop ultra-high depth outliers\n",
    "q = np.quantile(adata_ctrl.obs[\"nCount_RNA\"].values, 0.99)\n",
    "keep_cells = adata_ctrl.obs[\"nCount_RNA\"].values <= q\n",
    "adata_ctrl = adata_ctrl[keep_cells].copy()\n",
    "print(\"Control cells after 99% depth trim:\", adata_ctrl.n_obs)\n",
    "\n",
    "# Normalize and log\n",
    "sc.pp.normalize_total(adata_ctrl, target_sum=1e4, inplace=True)\n",
    "X = adata_ctrl.X.tocsr(copy=True)\n",
    "X.data = np.log1p(X.data).astype(np.float32)\n",
    "\n",
    "# Scale per-gene variance without densifying\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "svd = TruncatedSVD(n_components=EMBED_DIM, random_state=SEED)\n",
    "svd.fit(X)\n",
    "\n",
    "Z = svd.transform(X)\n",
    "obs = adata_ctrl.obs\n",
    "print(\"corr(SVD1, nCount_RNA):\", float(np.corrcoef(Z[:,0], obs[\"nCount_RNA\"].values)[0,1]))\n",
    "print(\"corr(SVD1, percent.mt):\", float(np.corrcoef(Z[:,0], obs[\"percent.mt\"].values)[0,1]))\n",
    "print(\"cumEVR@32:\", float(np.cumsum(svd.explained_variance_ratio_)[min(31, EMBED_DIM-1)]))\n",
    "\n",
    "gene_emb = svd.components_.T.astype(np.float32)\n",
    "gene2emb = {g: gene_emb[i] for i, g in enumerate(gene_columns)}\n",
    "emb_fallback = gene_emb.mean(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04800892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge {'mae': 0.028515085787512363, 'mae_base': 0.028515887749381363, 'mae_ratio': 0.9999718415976421, 'cos': 0.32098835660144687, 'cos_base': 0.32091827150434254, 'proxy_score': 0.32097931808214947}\n",
      "ridge_blend {'mae': 0.028515319898724557, 'mae_base': 0.028515887749381363, 'mae_ratio': 0.999980051449148, 'cos': 0.3209677147679031, 'cos_base': 0.32091827150434254, 'proxy_score': 0.3209613119271232}\n",
      "knn5 {'mae': 0.031157795782200993, 'mae_base': 0.028515887749381363, 'mae_ratio': 1.0926468417673618, 'cos': 0.21711297146539438, 'cos_base': 0.32091827150434254, 'proxy_score': 0.23722780257839052}\n",
      "knn10 {'mae': 0.029851229628548026, 'mae_base': 0.028515887749381363, 'mae_ratio': 1.0468279593493517, 'cos': 0.25586538447532803, 'cos_base': 0.32091827150434254, 'proxy_score': 0.2678470382984449}\n",
      "knn10_blend {'mae': 0.029170638346113265, 'mae_base': 0.028515887749381363, 'mae_ratio': 1.0229608693765895, 'cos': 0.2837439299561083, 'cos_base': 0.32091827150434254, 'proxy_score': 0.29025893726823065}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "def cosine(a, b, eps=1e-9):\n",
    "    na = np.linalg.norm(a)\n",
    "    nb = np.linalg.norm(b)\n",
    "    if na < eps or nb < eps:\n",
    "        return 0.0\n",
    "    return float(np.dot(a, b) / (na * nb))\n",
    "\n",
    "def loocv_eval(D, genes, gene2emb, emb_fallback, K_out=32, alpha=10.0, blend=1.0, knn_k=None):\n",
    "    n, d = D.shape\n",
    "    maes, maes_base, coss, coss_base = [], [], [], []\n",
    "\n",
    "    for i in range(n):\n",
    "        tr = np.ones(n, dtype=bool)\n",
    "        tr[i] = False\n",
    "\n",
    "        D_tr = D[tr]\n",
    "        D_va = D[i]\n",
    "        genes_tr = [genes[j] for j in np.where(tr)[0]]\n",
    "        g_va = genes[i]\n",
    "\n",
    "        delta_base = D_tr.mean(axis=0)\n",
    "\n",
    "        out_pca = PCA(n_components=min(K_out, D_tr.shape[0]-1), random_state=0)\n",
    "        C_tr = out_pca.fit_transform(D_tr)\n",
    "\n",
    "        X_tr = np.vstack([gene2emb.get(g, emb_fallback) for g in genes_tr]).astype(np.float32)\n",
    "        x_va = gene2emb.get(g_va, emb_fallback).astype(np.float32)[None, :]\n",
    "\n",
    "        if knn_k is None:\n",
    "            reg = Ridge(alpha=alpha, random_state=0)\n",
    "            reg.fit(X_tr, C_tr)\n",
    "            c_hat = reg.predict(x_va)\n",
    "        else:\n",
    "            knn = KNeighborsRegressor(n_neighbors=knn_k, metric=\"cosine\", algorithm=\"brute\", weights=\"distance\")\n",
    "            knn.fit(X_tr, C_tr)\n",
    "            c_hat = knn.predict(x_va)\n",
    "\n",
    "        d_hat = out_pca.inverse_transform(c_hat)[0].astype(np.float32)\n",
    "        d_hat = (1.0 - blend) * delta_base + blend * d_hat\n",
    "\n",
    "        # baseline predictor for ratio: mean-delta\n",
    "        d0 = delta_base\n",
    "\n",
    "        mae = float(np.mean(np.abs(D_va - d_hat)))\n",
    "        mae0 = float(np.mean(np.abs(D_va - d0)))\n",
    "        cosv = max(0.0, cosine(D_va, d_hat))\n",
    "        cos0 = max(0.0, cosine(D_va, d0))\n",
    "\n",
    "        maes.append(mae)\n",
    "        maes_base.append(mae0)\n",
    "        coss.append(cosv)\n",
    "        coss_base.append(cos0)\n",
    "\n",
    "    mae_mean = float(np.mean(maes))\n",
    "    mae0_mean = float(np.mean(maes_base))\n",
    "    cos_mean = float(np.mean(coss))\n",
    "    cos0_mean = float(np.mean(coss_base))\n",
    "    ratio = mae_mean / (mae0_mean + 1e-9)\n",
    "\n",
    "    return {\n",
    "        \"mae\": mae_mean,\n",
    "        \"mae_base\": mae0_mean,\n",
    "        \"mae_ratio\": ratio,\n",
    "        \"cos\": cos_mean,\n",
    "        \"cos_base\": cos0_mean,\n",
    "        \"proxy_score\": ratio * cos_mean,\n",
    "    }\n",
    "\n",
    "# Load deltas\n",
    "df_means = pd.read_csv(\"data/training_data_means.csv\")\n",
    "gene_columns = [c for c in df_means.columns if c != \"pert_symbol\"]\n",
    "baseline_mask = df_means[\"pert_symbol\"].astype(str) == \"non-targeting\"\n",
    "x_base = df_means.loc[baseline_mask, gene_columns].iloc[0].to_numpy(np.float32)\n",
    "\n",
    "df_train = df_means.loc[~baseline_mask].reset_index(drop=True)\n",
    "genes = df_train[\"pert_symbol\"].astype(str).tolist()\n",
    "D = df_train[gene_columns].to_numpy(np.float32) - x_base[None, :]\n",
    "\n",
    "# Try a few configs\n",
    "tests = [\n",
    "    (\"ridge\", dict(K_out=32, alpha=10.0, blend=1.0, knn_k=None)),\n",
    "    (\"ridge_blend\", dict(K_out=32, alpha=10.0, blend=0.7, knn_k=None)),\n",
    "    (\"knn5\", dict(K_out=32, alpha=0.0, blend=1.0, knn_k=5)),\n",
    "    (\"knn10\", dict(K_out=32, alpha=0.0, blend=1.0, knn_k=10)),\n",
    "    (\"knn10_blend\", dict(K_out=32, alpha=0.0, blend=0.7, knn_k=10)),\n",
    "]\n",
    "\n",
    "for name, cfg in tests:\n",
    "    out = loocv_eval(D, genes, gene2emb, emb_fallback, **cfg)\n",
    "    print(name, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85f7b955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control cells: 1015 Genes: 19226\n",
      "corr(SVD1, nCount_RNA): 0.490323181762857\n",
      "Missing training pert genes from h5ad var_names: 0\n",
      "Missing list: []\n",
      "8-gene embedding availability: {'BRD4': True, 'CHD4': True, 'DNAJA3': True, 'INO80': True, 'KAT8': True, 'KDM4A': True, 'PMEL': True, 'SETD1A': True}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "from scipy import sparse\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "SEED = 6\n",
    "EMBED_DIM = 128  # try 64/128/256\n",
    "\n",
    "df_means = pd.read_csv(\"data/training_data_means.csv\")\n",
    "baseline_mask = df_means[\"pert_symbol\"].astype(str) == \"non-targeting\"\n",
    "df_train = df_means.loc[~baseline_mask].reset_index(drop=True)\n",
    "train_genes = df_train[\"pert_symbol\"].astype(str).tolist()\n",
    "\n",
    "adata = ad.read_h5ad(\"Data/training_cells.h5ad\")\n",
    "ctrl = adata[adata.obs[\"sgrna_symbol\"].astype(str) == \"non-targeting\"].copy()\n",
    "\n",
    "# Trim crazy depth outliers (you already did 99%)\n",
    "q = np.quantile(ctrl.obs[\"nCount_RNA\"].values, 0.99)\n",
    "ctrl = ctrl[ctrl.obs[\"nCount_RNA\"].values <= q].copy()\n",
    "print(\"Control cells:\", ctrl.n_obs, \"Genes:\", ctrl.n_vars)\n",
    "\n",
    "# Normalize + log1p\n",
    "sc.pp.normalize_total(ctrl, target_sum=1e4, inplace=True)\n",
    "X = ctrl.X.tocsr(copy=True)\n",
    "X.data = np.log1p(X.data).astype(np.float32)\n",
    "\n",
    "# Per-gene scaling (sparse-friendly)\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "svd = TruncatedSVD(n_components=EMBED_DIM, random_state=SEED)\n",
    "svd.fit(X)\n",
    "\n",
    "Z = svd.transform(X)\n",
    "print(\"corr(SVD1, nCount_RNA):\", float(np.corrcoef(Z[:,0], ctrl.obs[\"nCount_RNA\"].values)[0,1]))\n",
    "\n",
    "# Gene embeddings for ALL var_names\n",
    "gene_emb = svd.components_.T.astype(np.float32)          # (n_genes, EMBED_DIM)\n",
    "var_names = ctrl.var_names.astype(str).tolist()\n",
    "gene2emb_all = {g: gene_emb[i] for i, g in enumerate(var_names)}\n",
    "emb_fallback = gene_emb.mean(axis=0)\n",
    "\n",
    "# Coverage check for training perturbation genes\n",
    "missing = sorted({g for g in train_genes if g not in gene2emb_all})\n",
    "print(\"Missing training pert genes from h5ad var_names:\", len(missing))\n",
    "print(\"Missing list:\", missing)\n",
    "\n",
    "# Also check the 8 you found\n",
    "check8 = ['BRD4','CHD4','DNAJA3','INO80','KAT8','KDM4A','PMEL','SETD1A']\n",
    "print(\"8-gene embedding availability:\", {g: (g in gene2emb_all) for g in check8})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f9ddb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K_out': 48, 'model': 'krr_rbf', 'params': {'alpha': 0.1, 'gamma': 0.2}, 'blend': 1.0, 'mae_ratio': 0.9997262433387063, 'cos': 0.32172345370054245, 'cos_base': 0.32091827150434254, 'proxy': 0.3216353797619975}\n",
      "{'K_out': 48, 'model': 'krr_rbf', 'params': {'alpha': 0.1, 'gamma': 0.2}, 'blend': 1.0, 'mae_ratio': 0.9997262433387063, 'cos': 0.32172345370054245, 'cos_base': 0.32091827150434254, 'proxy': 0.3216353797619975}\n",
      "{'K_out': 48, 'model': 'krr_rbf', 'params': {'alpha': 0.1, 'gamma': 0.2}, 'blend': 1.0, 'mae_ratio': 0.9997262433387063, 'cos': 0.32172345370054245, 'cos_base': 0.32091827150434254, 'proxy': 0.3216353797619975}\n",
      "{'K_out': 48, 'model': 'krr_rbf', 'params': {'alpha': 0.1, 'gamma': 0.2}, 'blend': 1.0, 'mae_ratio': 0.9997262433387063, 'cos': 0.32172345370054245, 'cos_base': 0.32091827150434254, 'proxy': 0.3216353797619975}\n",
      "{'K_out': 48, 'model': 'krr_rbf', 'params': {'alpha': 0.1, 'gamma': 0.2}, 'blend': 1.0, 'mae_ratio': 0.9997262433387063, 'cos': 0.32172345370054245, 'cos_base': 0.32091827150434254, 'proxy': 0.3216353797619975}\n",
      "{'K_out': 48, 'model': 'krr_rbf', 'params': {'alpha': 0.1, 'gamma': 0.2}, 'blend': 1.0, 'mae_ratio': 0.9997262433387063, 'cos': 0.32172345370054245, 'cos_base': 0.32091827150434254, 'proxy': 0.3216353797619975}\n",
      "{'K_out': 48, 'model': 'krr_rbf', 'params': {'alpha': 0.1, 'gamma': 0.2}, 'blend': 1.0, 'mae_ratio': 0.9997262433387063, 'cos': 0.32172345370054245, 'cos_base': 0.32091827150434254, 'proxy': 0.3216353797619975}\n",
      "{'K_out': 48, 'model': 'krr_rbf', 'params': {'alpha': 0.1, 'gamma': 0.2}, 'blend': 1.0, 'mae_ratio': 0.9997262433387063, 'cos': 0.32172345370054245, 'cos_base': 0.32091827150434254, 'proxy': 0.3216353797619975}\n",
      "{'K_out': 48, 'model': 'krr_rbf', 'params': {'alpha': 0.1, 'gamma': 0.2}, 'blend': 1.0, 'mae_ratio': 0.9997262433387063, 'cos': 0.32172345370054245, 'cos_base': 0.32091827150434254, 'proxy': 0.3216353797619975}\n",
      "{'K_out': 48, 'model': 'krr_rbf', 'params': {'alpha': 0.1, 'gamma': 0.2}, 'blend': 1.0, 'mae_ratio': 0.9997262433387063, 'cos': 0.32172345370054245, 'cos_base': 0.32091827150434254, 'proxy': 0.3216353797619975}\n",
      "{'K_out': 48, 'model': 'krr_rbf', 'params': {'alpha': 0.1, 'gamma': 0.2}, 'blend': 1.0, 'mae_ratio': 0.9997262433387063, 'cos': 0.32172345370054245, 'cos_base': 0.32091827150434254, 'proxy': 0.3216353797619975}\n",
      "{'K_out': 48, 'model': 'krr_rbf', 'params': {'alpha': 0.1, 'gamma': 0.2}, 'blend': 1.0, 'mae_ratio': 0.9997262433387063, 'cos': 0.32172345370054245, 'cos_base': 0.32091827150434254, 'proxy': 0.3216353797619975}\n",
      "{'K_out': 48, 'model': 'krr_poly', 'params': {'alpha': 1, 'degree': 3, 'gamma': 1.0, 'coef0': 1.0}, 'blend': 1.0, 'mae_ratio': 0.9997076174677412, 'cos': 0.3216878210194409, 'cos_base': 0.32091827150434254, 'proxy': 0.32159376511973436}\n",
      "{'K_out': 48, 'model': 'krr_poly', 'params': {'alpha': 1, 'degree': 3, 'gamma': 1.0, 'coef0': 1.0}, 'blend': 1.0, 'mae_ratio': 0.9997076174677412, 'cos': 0.3216878210194409, 'cos_base': 0.32091827150434254, 'proxy': 0.32159376511973436}\n",
      "{'K_out': 48, 'model': 'krr_poly', 'params': {'alpha': 1, 'degree': 3, 'gamma': 1.0, 'coef0': 1.0}, 'blend': 1.0, 'mae_ratio': 0.9997076174677412, 'cos': 0.3216878210194409, 'cos_base': 0.32091827150434254, 'proxy': 0.32159376511973436}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "def cosine(a, b, eps=1e-9):\n",
    "    na = np.linalg.norm(a); nb = np.linalg.norm(b)\n",
    "    if na < eps or nb < eps: return 0.0\n",
    "    return float(np.dot(a, b) / (na * nb))\n",
    "\n",
    "def loocv_proxy(D, genes, gene2emb, emb_fallback, K_out, model_kind, params, blend):\n",
    "    n, d = D.shape\n",
    "    maes, maes0, coss, coss0 = [], [], [], []\n",
    "\n",
    "    for i in range(n):\n",
    "        tr = np.ones(n, dtype=bool); tr[i] = False\n",
    "        D_tr, D_va = D[tr], D[i]\n",
    "        genes_tr = [genes[j] for j in np.where(tr)[0]]\n",
    "        g_va = genes[i]\n",
    "\n",
    "        base = D_tr.mean(axis=0)\n",
    "\n",
    "        pca = PCA(n_components=min(K_out, D_tr.shape[0]-1), random_state=0)\n",
    "        C_tr = pca.fit_transform(D_tr)\n",
    "\n",
    "        X_tr = np.vstack([gene2emb.get(g, emb_fallback) for g in genes_tr]).astype(np.float32)\n",
    "        x_va = gene2emb.get(g_va, emb_fallback).astype(np.float32)[None, :]\n",
    "\n",
    "        if model_kind == \"ridge\":\n",
    "            reg = Ridge(alpha=params[\"alpha\"], random_state=0)\n",
    "        elif model_kind == \"krr_rbf\":\n",
    "            reg = KernelRidge(alpha=params[\"alpha\"], kernel=\"rbf\", gamma=params[\"gamma\"])\n",
    "        elif model_kind == \"krr_poly\":\n",
    "            reg = KernelRidge(alpha=params[\"alpha\"], kernel=\"polynomial\", degree=params[\"degree\"], gamma=params.get(\"gamma\", 1.0), coef0=params.get(\"coef0\", 1.0))\n",
    "        else:\n",
    "            raise ValueError(model_kind)\n",
    "\n",
    "        reg.fit(X_tr, C_tr)\n",
    "        c_hat = reg.predict(x_va)\n",
    "        d_hat = pca.inverse_transform(c_hat)[0].astype(np.float32)\n",
    "\n",
    "        d_hat = (1.0 - blend) * base + blend * d_hat\n",
    "\n",
    "        mae = float(np.mean(np.abs(D_va - d_hat)))\n",
    "        mae0 = float(np.mean(np.abs(D_va - base)))\n",
    "        cosv = max(0.0, cosine(D_va, d_hat))\n",
    "        cos0 = max(0.0, cosine(D_va, base))\n",
    "\n",
    "        maes.append(mae); maes0.append(mae0)\n",
    "        coss.append(cosv); coss0.append(cos0)\n",
    "\n",
    "    mae_m = float(np.mean(maes)); mae0_m = float(np.mean(maes0))\n",
    "    cos_m = float(np.mean(coss)); cos0_m = float(np.mean(coss0))\n",
    "    ratio = mae_m / (mae0_m + 1e-9)\n",
    "    return {\"K_out\": K_out, \"model\": model_kind, \"params\": params, \"blend\": blend,\n",
    "            \"mae_ratio\": ratio, \"cos\": cos_m, \"cos_base\": cos0_m, \"proxy\": ratio * cos_m}\n",
    "\n",
    "df_means = pd.read_csv(\"data/training_data_means.csv\")\n",
    "gene_cols = [c for c in df_means.columns if c != \"pert_symbol\"]\n",
    "baseline_mask = df_means[\"pert_symbol\"].astype(str) == \"non-targeting\"\n",
    "x_base = df_means.loc[baseline_mask, gene_cols].iloc[0].to_numpy(np.float32)\n",
    "\n",
    "df_train = df_means.loc[~baseline_mask].reset_index(drop=True)\n",
    "genes = df_train[\"pert_symbol\"].astype(str).tolist()\n",
    "D = df_train[gene_cols].to_numpy(np.float32) - x_base[None, :]\n",
    "\n",
    "gene2emb = gene2emb_all\n",
    "\n",
    "grid = []\n",
    "for K_out in [16, 24, 32, 48]:\n",
    "    for blend in [0.6, 0.8, 1.0]:\n",
    "        for alpha in [0.1, 1, 10, 100]:\n",
    "            grid.append((\"ridge\", {\"alpha\": alpha}))\n",
    "        for alpha in [0.01, 0.1, 1]:\n",
    "            for gamma in [0.01, 0.05, 0.1, 0.2, 0.5, 1.0]:\n",
    "                grid.append((\"krr_rbf\", {\"alpha\": alpha, \"gamma\": gamma}))\n",
    "        for alpha in [0.01, 0.1, 1]:\n",
    "            for degree in [2, 3]:\n",
    "                grid.append((\"krr_poly\", {\"alpha\": alpha, \"degree\": degree, \"gamma\": 1.0, \"coef0\": 1.0}))\n",
    "\n",
    "results = []\n",
    "for model_kind, params in grid:\n",
    "    out = loocv_proxy(D, genes, gene2emb, emb_fallback, K_out, model_kind, params, blend)\n",
    "    results.append(out)\n",
    "\n",
    "# Print top 15 by proxy\n",
    "results_sorted = sorted(results, key=lambda x: x[\"proxy\"], reverse=True)\n",
    "for r in results_sorted[:15]:\n",
    "    print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2b4d9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " raw mean\n",
      "  mean(abs(diff)): 2.5708224773406982\n",
      "  max(abs(diff)) : 287.5828552246094\n",
      "  L2(diff)       : 883.6790771484375\n",
      "  corr(base_df, vec): 0.7733315105723955\n",
      "\n",
      " norm1e4 + mean(log1p)\n",
      "  mean(abs(diff)): 0.11021880060434341\n",
      "  max(abs(diff)) : 1.863661766052246\n",
      "  L2(diff)       : 17.3148193359375\n",
      "  corr(base_df, vec): 0.9990306464348331\n",
      "\n",
      " norm1e4 + mean(log2)\n",
      "  mean(abs(diff)): 0.10423404723405838\n",
      "  max(abs(diff)) : 0.4308958053588867\n",
      "  L2(diff)       : 11.10219669342041\n",
      "  corr(base_df, vec): 0.9990306489846221\n",
      "\n",
      " norm1e4 + log1p(mean)\n",
      "  mean(abs(diff)): 0.07655708491802216\n",
      "  max(abs(diff)) : 1.8306965827941895\n",
      "  L2(diff)       : 15.459739685058594\n",
      "  corr(base_df, vec): 0.9952569724709338\n",
      "\n",
      " norm1e4 + log2(mean)\n",
      "  mean(abs(diff)): 0.1808294951915741\n",
      "  max(abs(diff)) : 1.1035455465316772\n",
      "  L2(diff)       : 17.61606788635254\n",
      "  corr(base_df, vec): 0.9952569724133998\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "from scipy import sparse\n",
    "\n",
    "df_means = pd.read_csv(\"data/training_data_means.csv\")\n",
    "gene_cols = [c for c in df_means.columns if c != \"pert_symbol\"]\n",
    "base_df = df_means.loc[df_means[\"pert_symbol\"].astype(str)==\"non-targeting\", gene_cols].iloc[0].to_numpy(np.float32)\n",
    "\n",
    "adata = ad.read_h5ad(\"Data/training_cells.h5ad\")\n",
    "ctrl = adata[adata.obs[\"sgrna_symbol\"].astype(str)==\"non-targeting\"][:, gene_cols].copy()\n",
    "X_raw = ctrl.X.tocsr()\n",
    "\n",
    "def stats(name, vec):\n",
    "    diff = base_df - vec\n",
    "    print(\"\\n\", name)\n",
    "    print(\"  mean(abs(diff)):\", float(np.mean(np.abs(diff))))\n",
    "    print(\"  max(abs(diff)) :\", float(np.max(np.abs(diff))))\n",
    "    print(\"  L2(diff)       :\", float(np.linalg.norm(diff)))\n",
    "    print(\"  corr(base_df, vec):\", float(np.corrcoef(base_df, vec)[0,1]))\n",
    "\n",
    "def mean_of_log(X, log_kind):\n",
    "    X = X.tocsr(copy=True)\n",
    "    if log_kind == \"log1p\":\n",
    "        X.data = np.log1p(X.data).astype(np.float32)\n",
    "    elif log_kind == \"log2\":\n",
    "        X.data = np.log2(X.data + 1.0).astype(np.float32)\n",
    "    else:\n",
    "        raise ValueError\n",
    "    return np.asarray(X.mean(axis=0)).ravel().astype(np.float32)\n",
    "\n",
    "def log_of_mean(X, log_kind):\n",
    "    m = np.asarray(X.mean(axis=0)).ravel().astype(np.float32)\n",
    "    if log_kind == \"log1p\":\n",
    "        return np.log1p(m).astype(np.float32)\n",
    "    elif log_kind == \"log2\":\n",
    "        return np.log2(m + 1.0).astype(np.float32)\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "# Variant 0: raw means (no norm, no log)\n",
    "stats(\"raw mean\", np.asarray(X_raw.mean(axis=0)).ravel().astype(np.float32))\n",
    "\n",
    "# Normalize total first\n",
    "ctrl2 = ctrl.copy()\n",
    "sc.pp.normalize_total(ctrl2, target_sum=1e4, inplace=True)\n",
    "Xn = ctrl2.X.tocsr()\n",
    "\n",
    "# Mean of log\n",
    "stats(\"norm1e4 + mean(log1p)\", mean_of_log(Xn, \"log1p\"))\n",
    "stats(\"norm1e4 + mean(log2)\",  mean_of_log(Xn, \"log2\"))\n",
    "\n",
    "# Log of mean\n",
    "stats(\"norm1e4 + log1p(mean)\", log_of_mean(Xn, \"log1p\"))\n",
    "stats(\"norm1e4 + log2(mean)\",  log_of_mean(Xn, \"log2\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
